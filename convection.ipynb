{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from reservoir import Reservoir\n",
    "import data_utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport reservoir\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set()\n",
    "\n",
    "import pickle\n",
    "\n",
    "# TODO: check if the boundery changes the performance\n",
    "\n",
    "def load_input(path, sequence_length=None, n_repeat=1, derivative_order=0, reshape_1D=True):\n",
    "    T = np.load(path)[1:-1, :, :] # skipping the boundary layers\n",
    "    \n",
    "    if sequence_length is not None:\n",
    "        T_interp = np.zeros((T.shape[0], T.shape[1], sequence_length))\n",
    "        sequence = np.arange(T.shape[2])\n",
    "        sequence_new = np.linspace(0, T.shape[2], sequence_length)\n",
    "        for xi in range(T.shape[0]):\n",
    "            for yi in range(T.shape[1]):\n",
    "                T_interp[xi, yi, :] = np.interp(sequence_new, sequence, T[xi, yi, :])\n",
    "        T = T_interp\n",
    "        \n",
    "    if derivative_order==2:\n",
    "        for i in range(derivative_order):\n",
    "                T = np.gradient(T, axis= (0, 1))\n",
    "        T = T[0][0] + T[-1][-1] # get rid of mixed derivatives\n",
    "    if reshape_1D:\n",
    "        x_dim, y_dim, sequence_length = T.shape\n",
    "        T = np.transpose(T.reshape((x_dim*y_dim, sequence_length))).reshape((1, sequence_length, x_dim*y_dim))\n",
    "#         T_min = np.amin(T)\n",
    "#         T_max = np.amax(T)\n",
    "#         T = (T - (T_min + T_max)/2)/((T_max - T_min)/2)\n",
    "    if n_repeat>1:\n",
    "        T = np.tile(T, (n_repeat, 1, 1))\n",
    "    return T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reservoir Computing algorithm - Training phase:\n",
      "\n",
      "Initialization complete. \t\tElapsed time: 0.2599341869354248 s\n",
      "100%|██████████| 500/500 [00:00<00:00, 525.09it/s]\n"
     ]
    }
   ],
   "source": [
    "n_repeat = 1\n",
    "sequence_length = 500\n",
    "num_datasets =  4\n",
    "x_dim = 101\n",
    "y_dim = 24\n",
    "# raw_train_data = np.zeros((num_datasets, y_dim, x_dim, sequence_length))\n",
    "train_data_0 = np.zeros((num_datasets*n_repeat, sequence_length, y_dim*x_dim))\n",
    "train_data_1 = np.zeros((num_datasets*n_repeat, sequence_length, y_dim*x_dim))\n",
    "target_data = np.zeros((num_datasets*n_repeat, sequence_length, y_dim*x_dim))\n",
    "\n",
    "\n",
    "for i in range(num_datasets):\n",
    "    path = \"2D_convection_datasets/x_y_temperature_deltaT_\" + str(2*(i+1)) + \".npy\"\n",
    "    \n",
    "#     raw_train_data[i*n_repeat:(i+1)*n_repeat, :, :] = load_input(\n",
    "#         path, sequence_length=sequence_length, n_repeat = 1, derivative_order=0, reshape_1D=False)\n",
    "    \n",
    "    train_data_0[i*n_repeat:(i+1)*n_repeat, :, :] = load_input(\n",
    "        path, sequence_length=sequence_length, n_repeat = n_repeat, derivative_order=0, reshape_1D=True)\n",
    "    train_data_1[i*n_repeat:(i+1)*n_repeat, :, :] = load_input(\n",
    "        path, sequence_length=sequence_length, n_repeat = n_repeat, derivative_order=2, reshape_1D=True)\n",
    "    \n",
    "    target_data[i*n_repeat:(i+1)*n_repeat, :, :] = load_input(\n",
    "        path, sequence_length=sequence_length, n_repeat = n_repeat, derivative_order=0, reshape_1D=True)\n",
    "\n",
    "# train_data = np.concatenate((train_data_0, train_data_1))\n",
    "train_data = train_data_0\n",
    "\n",
    "parallel_res = int(train_data.shape[0]/target_data.shape[0])\n",
    "parallel_runs = train_data.shape[0]\n",
    "b = Reservoir(n_res=500, parallel_res = parallel_res, res_scale=1, res_encoding='phase', res_enc_param=np.pi,\n",
    "              input_scale=1, input_encoding='phase', input_enc_param = np.pi,\n",
    "              input_standardize = False, res_standardize = True, output_standardize = False,\n",
    "              scale_input_MinMax = (-1, 1), scale_res_MinMax = None, scale_output_MinMax = (-1, 1),\n",
    "              random_projection='simulation', weights_type='complex gaussian',\n",
    "              activation_fun='intensity', activation_param=1,\n",
    "              parallel_runs = parallel_runs,\n",
    "              bias_scale=0.2, leak_rate=0.3,\n",
    "              pred_horizon=5, rec_pred_steps=1, forget = 100,\n",
    "              train_method='ridge', train_param=1e1, \n",
    "              raw_input_feature = True, enc_input_feature = False,\n",
    "              verbose=1\n",
    "             )\n",
    "\n",
    "# Algorithm training\n",
    "# b.fit(train_data, y=target_data);\n",
    "true_output, concat_states = b.fit(train_data, y=target_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reservoir Computing algorithm - Testing phase:\n",
      "\n",
      "Initialization complete. \t\tElapsed time: 0.00027108192443847656 s\n",
      "100%|██████████| 500/500 [00:00<00:00, 1013.90it/s]\n",
      "Reservoir iterations complete. \t\tElapsed time: 0.6106622219085693 s\n",
      "Testing complete. \t\t\tElapsed time: 85.99850654602051 s\n",
      "Testing score: 0.03196298169526102\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# raw_test_data = load_input(\"2D_convection_datasets/x_y_temperature_deltaT_10.npy\", \n",
    "#                            sequence_length=sequence_length, n_repeat = 1, derivative_order=0, reshape_1D=False)\n",
    "test_data_0 = load_input(\"2D_convection_datasets/x_y_temperature_deltaT_10.npy\", \n",
    "                         sequence_length=sequence_length, n_repeat = 1, derivative_order=0,reshape_1D=True)\n",
    "test_data_1 = load_input(\"2D_convection_datasets/x_y_temperature_deltaT_10.npy\", \n",
    "                         sequence_length=sequence_length, n_repeat = 1, derivative_order=2,reshape_1D=True)\n",
    "# test_data = np.concatenate((test_data_0, test_data_1))\n",
    "test_data = test_data_0\n",
    "true_output = load_input(\"2D_convection_datasets/x_y_temperature_deltaT_10.npy\", \n",
    "                         sequence_length=sequence_length, n_repeat = 1, derivative_order=0, reshape_1D=True)\n",
    "# scalery = StandardScaler().fit(true_output[0])\n",
    "# scalery.transform(true_output[0], copy=False)\n",
    "n_sequence, sequence_length, spatial_points = test_data.shape\n",
    "\n",
    "# Algorithm testing\n",
    "b.parallel_runs = n_sequence\n",
    "pred_output, score = b.predict_and_score(test_data, true_output=true_output, detailed_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump information/read dumped information\n",
    "# file = open('reservoir_dumped', 'wb')\n",
    "# pickle.dump(b, file, protocol=4)\n",
    "# file.close()\n",
    "# file = open('reservoir_dumped', 'rb')\n",
    "# b = pickle.load(file)\n",
    "# file = open('reservoir_dumped', 'rb')\n",
    "\n",
    "np.save('prediction_n_res_5000_n_pred_100_dT_10_corrected_temperature', pred_output)\n",
    "# b.output_w = np.load('dumped_output_weights/output_weights_n_res_10000_n_pred_5.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one-step prediction at different times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # modifying back the datasets into their initial form\n",
    "pred_output_ = pred_output.reshape(\n",
    "    sequence_length-b.forget, b.pred_horizon, y_dim, x_dim)\n",
    "true_output_ = true_output[:, b.forget:, :].reshape(\n",
    "    sequence_length-b.forget, y_dim, x_dim)\n",
    "\n",
    "times = [415, 2*415, 3*415, 4*415, 5*415]\n",
    "T_true_max = np.amax([true_output_[j+1, :, :] for j in times])\n",
    "T_true_min = np.amin([true_output_[j+1, :, :] for j in times])\n",
    "T_pred_max = np.amax([pred_output_[j, 0, :, :] for j in times])\n",
    "T_pred_min = np.amin([pred_output_[j, 0, :, :] for j in times])\n",
    "T_diff_max = np.amax([true_output_[j+1, :, :] - pred_output_[j, 0, :, :] for j in times])\n",
    "T_diff_min = np.amin([true_output_[j+1, :, :] - pred_output_[j, 0, :, :] for j in times])\n",
    "\n",
    "n_fig = 5\n",
    "fig, axs = plt.subplots(3, n_fig, sharey=True, sharex=True, figsize=(20,5))\n",
    "\n",
    "for i in range(n_fig):\n",
    "    t = times[i]\n",
    "    im0 = axs[0, i].pcolormesh(true_output_[t+1, :, :], cmap='inferno', vmin=T_true_min, vmax=T_true_max)\n",
    "#     plt.ylabel('x')\n",
    "#     plt.xlabel('y')\n",
    "\n",
    "    im1 = axs[1, i].pcolormesh(pred_output_[t, 0, :, :], cmap='inferno', vmin=T_pred_min, vmax=T_pred_max)\n",
    "#     plt.ylabel('x')\n",
    "#     plt.xlabel('y')\n",
    "    \n",
    "    im2 = axs[2, i].pcolormesh(\n",
    "        true_output_[t+1, :, :] - pred_output_[t, 0, :, :], cmap='inferno', vmin=T_diff_min, vmax=T_diff_max)\n",
    "#     plt.ylabel('x')\n",
    "#     plt.xlabel('y')\n",
    "        \n",
    "fig.colorbar(im0, ax=axs[0, :].ravel().tolist(), shrink=1)\n",
    "fig.colorbar(im1, ax=axs[1, :].ravel().tolist(), shrink=1)\n",
    "fig.colorbar(im2, ax=axs[2, :].ravel().tolist(), shrink=1)\n",
    "plt.show\n",
    "# plt.savefig('one-step_prediction_at_different_times.png', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-step prediction starting from a given time moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifying back the datasets into their initial form\n",
    "# T_max = np.amax(raw_test_data)\n",
    "# T_min = np.amin(raw_test_data)\n",
    "# x_dim, y_dim, sequence_length = raw_test_data.shape\n",
    "# pred_output_ = pred_output.reshape(\n",
    "#     sequence_length-b.forget, b.pred_horizon, x_dim, y_dim)*((T_max - T_min)/2) + (T_max + T_min)/2\n",
    "# test_data_ = test_data[0, b.forget:].reshape(\n",
    "#     sequence_length-b.forget, x_dim, y_dim)*((T_max - T_min)/2) + (T_max + T_min)/2\n",
    "\n",
    "t = 1250\n",
    "pred_steps = [0, 25, 50, 75, 99]\n",
    "T_test_max = np.amax([test_data_[t+k+1, :, :] for k in pred_steps])\n",
    "T_test_min = np.amin([test_data_[t+k+1, :, :] for k in pred_steps])\n",
    "T_pred_max = np.amax([pred_output_[t, k, :, :] for k in pred_steps])\n",
    "T_pred_min = np.amin([pred_output_[t, k, :, :] for k in pred_steps])\n",
    "T_diff_max = np.amax([test_data_[t+k+1, :, :] - pred_output_[t, k, :, :] for k in pred_steps])\n",
    "T_diff_min = np.amin([test_data_[t+k+1, :, :] - pred_output_[t, k, :, :] for k in pred_steps])\n",
    "\n",
    "n_fig = 5\n",
    "fig, axs = plt.subplots(3, n_fig, sharey=True, sharex=True, figsize=(20,5))\n",
    "\n",
    "for i in range(n_fig):\n",
    "    \n",
    "    j = pred_steps[i]\n",
    "    im0 = axs[0, i].pcolormesh(test_data_[t+j+1, :, :], cmap='inferno', vmin=T_test_min, vmax=T_test_max)\n",
    "#     plt.ylabel('x')\n",
    "#     plt.xlabel('y')\n",
    "\n",
    "    im1 = axs[1, i].pcolormesh(pred_output_[t, j, :, :], cmap='inferno', vmin=T_pred_min, vmax=T_pred_max)\n",
    "#     plt.ylabel('x')\n",
    "#     plt.xlabel('y')\n",
    "    \n",
    "    im2 = axs[2, i].pcolormesh(\n",
    "        test_data_[t+1, :, :] - pred_output_[t, 0, :, :], cmap='inferno', vmin=T_diff_min, vmax=T_diff_max)\n",
    "#     plt.ylabel('x')\n",
    "#     plt.xlabel('y')\n",
    "    \n",
    "    \n",
    "fig.colorbar(im0, ax=axs[0, :].ravel().tolist(), shrink=1)\n",
    "fig.colorbar(im1, ax=axs[1, :].ravel().tolist(), shrink=1)\n",
    "fig.colorbar(im2, ax=axs[2, :].ravel().tolist(), shrink=1)\n",
    "plt.show\n",
    "# plt.savefig('multi-step_predictions_from_given_time.png', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_max = np.amax(raw_test_data)\n",
    "T_min = np.amin(raw_test_data)\n",
    "x_dim, y_dim, sequence_length = raw_test_data.shape\n",
    "pred_output_ = pred_output.reshape(sequence_length-b.forget, b.pred_horizon, x_dim, y_dim)\n",
    "true_data = test_data[0, b.forget:].reshape(sequence_length-b.forget, x_dim, y_dim)\n",
    "\n",
    "\n",
    "total_pred = b.pred_horizon*b.rec_pred_steps\n",
    "true_data_norm = true_data/np.std(true_data)\n",
    "pred_output_norm = pred_output_/np.std(true_data)\n",
    "length_input = pred_output_norm.shape[0] - total_pred\n",
    "rmse = np.zeros((length_input, total_pred))\n",
    "for n_input in range(1, length_input):\n",
    "    for n_pred in range(1, total_pred+1):\n",
    "        d1 = true_data_norm[n_input:n_input+n_pred, :, :]\n",
    "        d2 = pred_output_norm[n_input-1, 0:n_pred, :]\n",
    "        \n",
    "        rmse[n_input-1, n_pred-1] = np.sqrt(1./(n_pred*spatial_points)*np.sum((d1.flatten() - d2.flatten())**2))\n",
    "\n",
    "np.save('rmse_n_res_5000_n_pred_100_dT_10', rmse)\n",
    "\n",
    "plt.figure(1,figsize=(10,2))\n",
    "plt.title('RMSE')\n",
    "plt.ylabel('input length')\n",
    "plt.xlabel('Time')\n",
    "im=plt.pcolormesh(rmse[:,:], cmap='inferno')\n",
    "plt.colorbar(im)\n",
    "plt.show;\n",
    "plt.savefig('RMSE_map.png', bbox_inches='tight', dpi=600)\n",
    "\n",
    "plt.figure(2,figsize=(8,2))\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('Time')\n",
    "plt.plot(np.mean(rmse[:,:], axis=0))\n",
    "plt.show;\n",
    "plt.savefig('RMSE_averaged.png', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-step prediction for a given y crossection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pred = b.pred_horizon*b.rec_pred_steps\n",
    "n_input = 5*415 #round(pred_output.shape[0]/2-300)\n",
    "y = 2\n",
    "input_data = test_data_[:n_input, y, :]\n",
    "prediction = pred_output_[n_input, :, y, :]\n",
    "targetted_data = test_data_[n_input:n_input+total_pred, y, :]\n",
    "\n",
    "vmax = np.amax(np.concatenate((targetted_data, input_data, prediction)))\n",
    "vmin = np.amin(np.concatenate((targetted_data, input_data, prediction)))\n",
    "\n",
    "# plot training data\n",
    "fig, axs = plt.subplots(2, 1, sharex=False, figsize=(9,9))\n",
    "plt.ylabel('x')\n",
    "plt.xlabel('Time')\n",
    "datum = [\n",
    "    np.concatenate((input_data, targetted_data)), \n",
    "    np.concatenate((input_data, prediction)), \n",
    "    np.abs(targetted_data-prediction)]\n",
    "for i in range(2):\n",
    "    im=axs[i].pcolormesh(datum[i].T, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "fig.colorbar(im, ax=axs.ravel().tolist(), shrink=0.4)\n",
    "plt.savefig('prediction_target_2D.png')\n",
    "\n",
    "plt.figure(3,figsize=(9,2.5))\n",
    "im=plt.pcolormesh(datum[2].T, cmap='gray')\n",
    "plt.colorbar(im)\n",
    "plt.savefig('prediction_target_diff.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-step prediction for a given y crossection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pred = b.pred_horizon*b.rec_pred_steps\n",
    "n_input = 1600 #round(pred_output.shape[0]/2-300)\n",
    "y = 5\n",
    "input_data = test_data_[:n_input, y, :]\n",
    "prediction = pred_output_[n_input, :, y, :]\n",
    "targetted_data = test_data_[n_input:n_input+total_pred, y, :]\n",
    "\n",
    "vmax = np.amax(abs(np.concatenate((targetted_data, input_data, prediction))))\n",
    "vmin = np.min(abs(np.concatenate((targetted_data, input_data, prediction))))\n",
    "\n",
    "# plot training data\n",
    "fig, axs = plt.subplots(3, 1, sharex=False, figsize=(9,9))\n",
    "plt.suptitle('Trained, tested, predicted and abs(tested-predicted) plots                       ')\n",
    "plt.ylabel('x')\n",
    "plt.xlabel('\\Lambda_{max} * Time')\n",
    "datum = [input_data, targetted_data, prediction, np.abs(targetted_data-prediction)]\n",
    "for i in range(3):\n",
    "    im=axs[i].pcolormesh(datum[i].T, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "fig.colorbar(im, ax=axs.ravel().tolist(), shrink=0.4)\n",
    "\n",
    "plt.figure(3,figsize=(9,2.5))\n",
    "im=plt.pcolormesh(datum[3].T, cmap='gray')\n",
    "plt.colorbar(im)\n",
    "# # plt.savefig('DND_input_data.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
